---
title: "Practical Machine Learning Course Project"
author: "cz"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(caret)
library(doParallel)
library(randomForest)
library(xgboost)
library(glmnet)
```


# Introduction

The goal of this project is to predict the manner in which participants performed the exercise (`classe` variable) using sensor measurements collected during the activities. The dataset contains 160 variables, including accelerometer and gyroscope readings from participants’ smartphones and forearm sensors. Accurately predicting `classe` is essential to assess performance and improve training outcomes.

This project demonstrates how data preprocessing, model selection, and cross-validation were applied to build an effective predictive model. The final model is then applied to 20 test cases for automated grading in the course.


## Step 1: Data Loading and Cleaning
```{r}
train_raw <- read.csv("pml-training.csv")
test_raw  <- read.csv("pml-testing.csv")

# Outcome variable
y <- train_raw$classe

# Remove non-predictive variables
drops <- c("X", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2",
           "cvtd_timestamp", "new_window", "num_window")
x <- train_raw[, !(names(train_raw) %in% drops)]

```


## Step 2: Train / Validation Split

```{r}
set.seed(2025)
train_index <- createDataPartition(y, p = 0.7, list = FALSE)
x_train <- x[train_index, ]
y_train <- y[train_index]
x_valid <- x[-train_index, ]
y_valid <- y[-train_index]

# Keep numeric predictors only
x_train <- x_train[, sapply(x_train, is.numeric)]
x_valid <- x_valid[, sapply(x_valid, is.numeric)]

# Remove columns with NAs (based on training set)
x_train <- x_train[, colSums(is.na(x_train)) == 0]
x_valid <- x_valid[, names(x_train)]  # align validation

```


## Step 3: Convert Outcome to Factor

```{r}
y_train <- as.factor(y_train)
y_valid <- as.factor(y_valid)

```


## Step 4: Parallel Processing Setup

```{r}
cl <- makeCluster(parallel::detectCores() - 1)
registerDoParallel(cl)

```


## Step 5: Cross-Validation Settings

```{r}
ctrl <- trainControl(
  method = "cv",
  number = 5,           # 5-fold CV
  classProbs = TRUE,
  savePredictions = "final"
)

```


## Step 6: Random Forest Model

```{r}
set.seed(2025)
rf_mod <- train(
  x = x_train, y = y_train,
  method = "rf",
  metric = "Accuracy",
  trControl = ctrl,
  ntree = 500
)

```


## Step 7: XGBoost Model

```{r}
set.seed(2025)
xgb_mod <- train(
  x = x_train, y = y_train,
  method = "xgbTree",
  metric = "Accuracy",
  tuneLength = 3,
  trControl = ctrl
)

```


## Step 8: Compare Models

```{r}
resamps <- resamples(list(RF = rf_mod, XGB = xgb_mod))
summary(resamps)

```


## Step 9: Stop Parallel Backend
```{r}
stopCluster(cl)
registerDoSEQ()

```



## Step 10: Champion Model Selection

```{r}
mods <- list(RF = rf_mod, XGB = xgb_mod)
accs <- sapply(mods, function(m) max(m$results$Accuracy, na.rm = TRUE))
champ_name <- names(which.max(accs))
champ <- mods[[champ_name]]
cat("Champion model:", champ_name, "\n")

```

## Step 11: Validation Results

The champion XGBoost model was evaluated on the validation set. Overall accuracy and class-level metrics indicate that the model generalizes well to unseen data.

```{r}
pred_valid <- predict(champ, x_valid)
cm <- confusionMatrix(pred_valid, y_valid)
cm

```

## Step 12: Variable Importance

The top 20 predictors indicate which sensor measurements are most influential in predicting the exercise class.

```{r}
plot(varImp(champ), top = 20, main = "Top 20 Predictors")

```



## Step 13: Test Set Predictions

The final XGBoost model was applied to the 20 test cases. Predictions were generated and saved in the required format for submission.

```{r}
x_test <- test_raw[, names(x_train)]
final_preds <- predict(champ, x_test)
final_preds

```


## Write Predictions to Files (for Course Quiz Submission)

```{r}
pml_write_files <- function(x){
  n <- length(x)
  for(i in 1:n){
    filename <- paste0("problem_id_", i, ".txt")
    write.table(x[i], file=filename, quote=FALSE, row.names=FALSE, col.names=FALSE)
  }
}

pml_write_files(final_preds)


```


# Conclusion

- XGBoost was selected as the champion model due to higher cross-validation accuracy.

- Validation accuracy is very high (≈0.995), indicating strong generalization.

- Expected out-of-sample error is low based on 5-fold CV.

- Top predictors include key accelerometer and gyroscope measurements.

- Predictions for the 20 test cases were generated and saved in the format required for Coursera submission.





